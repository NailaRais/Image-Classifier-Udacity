{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the workspace\n",
    "Check torch version and CUDA status if GPU is enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Should return True when GPU is enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Here you'll use `torchvision` to load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define your transforms for the training, validation, and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets with ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(valid_dir, transform=data_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the image datasets and the transforms, define the dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=32, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size=32, shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(image_datasets['test'], batch_size=32, shuffle=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "Now that the data is ready, it's time to build and train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, dataloaders, criterion, optimizer, epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()  # Accumulate the loss\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print(f\"Training Loss: {running_loss / len(dataloaders['train']):.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    return model  # Return the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "It's good practice to test your trained network on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(model, dataloaders, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = correct / total\n",
    "    print(f\"Test Loss: {running_loss / len(dataloaders['test']):.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "    return test_accuracy  # Return test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "Now that your network is trained, save the model so you can load it later for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, file_path='model_checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Checkpoint saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint(model_class, model_params, checkpoint_path='model_checkpoint.pth'):\n",
    "    model = model_class(**model_params)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = model_params['optimizer_class'](model.parameters(), **model_params['optimizer_params'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {checkpoint_path}. Model trained until epoch {epoch} with loss {loss}\")\n",
    "    return model, optimizer, epoch, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for classification\n",
    "Now you'll write a function to use a trained network for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(image_path, model=None, input_size=(224, 224), mean=None, std=None):\n",
    "    processed_image = process_image(image_path, input_size, mean, std)\n",
    "    processed_image = processed_image.unsqueeze(0)\n",
    "    if model is None:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(processed_image)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    if not hasattr(predict_class, 'imagenet_class_index'):\n",
    "        url = 'https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json'\n",
    "        response = requests.get(url)\n",
    "        predict_class.imagenet_class_index = response.json()\n",
    "    class_idx = predicted_class.item()\n",
    "    class_label = predict_class.imagenet_class_index[str(class_idx)][1]\n",
    "    return class_label, class_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage:\n",
    "image_path = 'assets/Flowers.png'\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "predicted_label, predicted_class_idx = predict_class(image_path, mean=mean, std=std)\n",
    "print(f'Predicted class: {predicted_label} (Class index: {predicted_class_idx})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_predictions(image_path, top5_labels, probs, image_tensor):\n",
    "    image_tensor = image_tensor.squeeze(0)\n",
    "    image = transforms.ToPILImage()(image_tensor)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Top 5 Predictions\")\n",
    "    for i in range(5):\n",
    "        plt.text(0, i*20, f'{top5_labels[i]}: {probs[i]*100:.2f}%', color='white', fontsize=12)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
