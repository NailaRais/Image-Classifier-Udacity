{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31caa59",
   "metadata": {
    "papermill": {
     "duration": 0.004149,
     "end_time": "2025-01-15T19:09:45.160889",
     "exception": false,
     "start_time": "2025-01-15T19:09:45.156740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the workspace\n",
    "Check torch version and CUDA status if GPU is enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436b5e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:45.169292Z",
     "iopub.status.busy": "2025-01-15T19:09:45.168620Z",
     "iopub.status.idle": "2025-01-15T19:09:46.348127Z",
     "shell.execute_reply": "2025-01-15T19:09:46.347400Z"
    },
    "papermill": {
     "duration": 1.184885,
     "end_time": "2025-01-15T19:09:46.349400",
     "exception": false,
     "start_time": "2025-01-15T19:09:45.164515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # Should return True when GPU is enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d366a",
   "metadata": {
    "papermill": {
     "duration": 0.004317,
     "end_time": "2025-01-15T19:09:46.357323",
     "exception": false,
     "start_time": "2025-01-15T19:09:46.353006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec759dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:46.364810Z",
     "iopub.status.busy": "2025-01-15T19:09:46.364363Z",
     "iopub.status.idle": "2025-01-15T19:09:47.332082Z",
     "shell.execute_reply": "2025-01-15T19:09:47.331384Z"
    },
    "papermill": {
     "duration": 0.972953,
     "end_time": "2025-01-15T19:09:47.333489",
     "exception": false,
     "start_time": "2025-01-15T19:09:46.360536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3e25b",
   "metadata": {
    "papermill": {
     "duration": 0.003329,
     "end_time": "2025-01-15T19:09:47.340659",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.337330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the data\n",
    "Here you'll use `torchvision` to load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078b7d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.348848Z",
     "iopub.status.busy": "2025-01-15T19:09:47.348157Z",
     "iopub.status.idle": "2025-01-15T19:09:47.351687Z",
     "shell.execute_reply": "2025-01-15T19:09:47.351161Z"
    },
    "papermill": {
     "duration": 0.008767,
     "end_time": "2025-01-15T19:09:47.352691",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.343924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c14977",
   "metadata": {
    "papermill": {
     "duration": 0.003277,
     "end_time": "2025-01-15T19:09:47.359282",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.356005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define your transforms for the training, validation, and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67341e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.367426Z",
     "iopub.status.busy": "2025-01-15T19:09:47.367205Z",
     "iopub.status.idle": "2025-01-15T19:09:47.372353Z",
     "shell.execute_reply": "2025-01-15T19:09:47.371789Z"
    },
    "papermill": {
     "duration": 0.010055,
     "end_time": "2025-01-15T19:09:47.373302",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.363247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01dc6e",
   "metadata": {
    "papermill": {
     "duration": 0.003342,
     "end_time": "2025-01-15T19:09:47.380004",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.376662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the datasets with ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81b7ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.387881Z",
     "iopub.status.busy": "2025-01-15T19:09:47.387354Z",
     "iopub.status.idle": "2025-01-15T19:09:47.418031Z",
     "shell.execute_reply": "2025-01-15T19:09:47.417293Z"
    },
    "papermill": {
     "duration": 0.036161,
     "end_time": "2025-01-15T19:09:47.419526",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.383365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(valid_dir, transform=data_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57613abd",
   "metadata": {
    "papermill": {
     "duration": 0.003332,
     "end_time": "2025-01-15T19:09:47.426495",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.423163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using the image datasets and the transforms, define the dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5567035a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.434670Z",
     "iopub.status.busy": "2025-01-15T19:09:47.434269Z",
     "iopub.status.idle": "2025-01-15T19:09:47.438498Z",
     "shell.execute_reply": "2025-01-15T19:09:47.437815Z"
    },
    "papermill": {
     "duration": 0.009403,
     "end_time": "2025-01-15T19:09:47.439634",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.430231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=32, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size=32, shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(image_datasets['test'], batch_size=32, shuffle=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f89b1",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2025-01-15T19:09:47.447562",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.444080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Label mapping\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d384d844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.455166Z",
     "iopub.status.busy": "2025-01-15T19:09:47.454789Z",
     "iopub.status.idle": "2025-01-15T19:09:47.458082Z",
     "shell.execute_reply": "2025-01-15T19:09:47.457557Z"
    },
    "papermill": {
     "duration": 0.008219,
     "end_time": "2025-01-15T19:09:47.459072",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.450853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662cf65",
   "metadata": {
    "papermill": {
     "duration": 0.003392,
     "end_time": "2025-01-15T19:09:47.465906",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.462514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building and training the classifier\n",
    "Now that the data is ready, it's time to build and train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f259355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.473829Z",
     "iopub.status.busy": "2025-01-15T19:09:47.473302Z",
     "iopub.status.idle": "2025-01-15T19:09:47.479057Z",
     "shell.execute_reply": "2025-01-15T19:09:47.478526Z"
    },
    "papermill": {
     "duration": 0.010731,
     "end_time": "2025-01-15T19:09:47.480088",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.469357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_network(model, dataloaders, criterion, optimizer, epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()  # Accumulate the loss\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print(f\"Training Loss: {running_loss / len(dataloaders['train']):.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    return model  # Return the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d838acc",
   "metadata": {
    "papermill": {
     "duration": 0.003345,
     "end_time": "2025-01-15T19:09:47.487022",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.483677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing your network\n",
    "It's good practice to test your trained network on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770af8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.494799Z",
     "iopub.status.busy": "2025-01-15T19:09:47.494405Z",
     "iopub.status.idle": "2025-01-15T19:09:47.499179Z",
     "shell.execute_reply": "2025-01-15T19:09:47.498605Z"
    },
    "papermill": {
     "duration": 0.009831,
     "end_time": "2025-01-15T19:09:47.500235",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.490404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_network(model, dataloaders, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = correct / total\n",
    "    print(f\"Test Loss: {running_loss / len(dataloaders['test']):.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "    return test_accuracy  # Return test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434dda4",
   "metadata": {
    "papermill": {
     "duration": 0.003449,
     "end_time": "2025-01-15T19:09:47.507228",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.503779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save the checkpoint\n",
    "Now that your network is trained, save the model so you can load it later for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1b9f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.514983Z",
     "iopub.status.busy": "2025-01-15T19:09:47.514576Z",
     "iopub.status.idle": "2025-01-15T19:09:47.518364Z",
     "shell.execute_reply": "2025-01-15T19:09:47.517773Z"
    },
    "papermill": {
     "duration": 0.008697,
     "end_time": "2025-01-15T19:09:47.519310",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.510613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, file_path='model_checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Checkpoint saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779b4ff",
   "metadata": {
    "papermill": {
     "duration": 0.00358,
     "end_time": "2025-01-15T19:09:47.526455",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.522875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the checkpoint\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9383c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.534240Z",
     "iopub.status.busy": "2025-01-15T19:09:47.533823Z",
     "iopub.status.idle": "2025-01-15T19:09:47.537787Z",
     "shell.execute_reply": "2025-01-15T19:09:47.537271Z"
    },
    "papermill": {
     "duration": 0.008939,
     "end_time": "2025-01-15T19:09:47.538797",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.529858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint(model_class, model_params, checkpoint_path='model_checkpoint.pth'):\n",
    "    model = model_class(**model_params)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = model_params['optimizer_class'](model.parameters(), **model_params['optimizer_params'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {checkpoint_path}. Model trained until epoch {epoch} with loss {loss}\")\n",
    "    return model, optimizer, epoch, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8dd80e",
   "metadata": {
    "papermill": {
     "duration": 0.003472,
     "end_time": "2025-01-15T19:09:47.545805",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.542333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference for classification\n",
    "Now you'll write a function to use a trained network for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11810861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.554041Z",
     "iopub.status.busy": "2025-01-15T19:09:47.553556Z",
     "iopub.status.idle": "2025-01-15T19:09:47.558346Z",
     "shell.execute_reply": "2025-01-15T19:09:47.557803Z"
    },
    "papermill": {
     "duration": 0.009902,
     "end_time": "2025-01-15T19:09:47.559311",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.549409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_class(image_path, model=None, input_size=(224, 224), mean=None, std=None):\n",
    "    processed_image = process_image(image_path, input_size, mean, std)\n",
    "    processed_image = processed_image.unsqueeze(0)\n",
    "    if model is None:\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(processed_image)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    if not hasattr(predict_class, 'imagenet_class_index'):\n",
    "        url = 'https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json'\n",
    "        response = requests.get(url)\n",
    "        predict_class.imagenet_class_index = response.json()\n",
    "    class_idx = predicted_class.item()\n",
    "    class_label = predict_class.imagenet_class_index[str(class_idx)][1]\n",
    "    return class_label, class_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f318a0",
   "metadata": {
    "papermill": {
     "duration": 0.003515,
     "end_time": "2025-01-15T19:09:47.566325",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.562810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example usage:\n",
    "image_path = 'assets/Flowers.png'\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "predicted_label, predicted_class_idx = predict_class(image_path, mean=mean, std=std)\n",
    "print(f'Predicted class: {predicted_label} (Class index: {predicted_class_idx})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3f136",
   "metadata": {
    "papermill": {
     "duration": 0.00347,
     "end_time": "2025-01-15T19:09:47.573332",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.569862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity Checking\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16398563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:09:47.581224Z",
     "iopub.status.busy": "2025-01-15T19:09:47.580847Z",
     "iopub.status.idle": "2025-01-15T19:09:47.585044Z",
     "shell.execute_reply": "2025-01-15T19:09:47.584391Z"
    },
    "papermill": {
     "duration": 0.009345,
     "end_time": "2025-01-15T19:09:47.586123",
     "exception": false,
     "start_time": "2025-01-15T19:09:47.576778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_image_with_predictions(image_path, top5_labels, probs, image_tensor):\n",
    "    image_tensor = image_tensor.squeeze(0)\n",
    "    image = transforms.ToPILImage()(image_tensor)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Top 5 Predictions\")\n",
    "    for i in range(5):\n",
    "        plt.text(0, i*20, f'{top5_labels[i]}: {probs[i]*100:.2f}%', color='white', fontsize=12)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.915701,
   "end_time": "2025-01-15T19:09:48.206099",
   "environment_variables": {},
   "exception": null,
   "input_path": "Notebook.ipynb",
   "output_path": "Executed_Notebook.ipynb",
   "parameters": {},
   "start_time": "2025-01-15T19:09:44.290398",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}